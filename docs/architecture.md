# MachinaMindAIAgent Systemarchitektur

## Ãœberblick

MachinaMindAIAgent ist ein vollstÃ¤ndiges Industrial AI System mit:

- **Backend**: Python (FastAPI, LangChain, RAG)
- **Frontend**: C++ Qt (MVP-Pattern)
- **Datenspeicherung**: SQLite/PostgreSQL
- **AI**: LLM + RAG fÃ¼r intelligente Analyse

---

## Systemarchitektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MachinaMindAIAgent                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  C++ Qt Frontend    â”‚              â”‚  Python Backend      â”‚
â”‚  (MVP Pattern)      â”‚â—„â”€â”€â”€REST/â”€â”€â”€â”€â–ºâ”‚  (FastAPI)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    JSON      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                      â”‚
         â”‚                             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                             â”‚                 â”‚
         â”‚                        â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
         â”‚                        â”‚   DB    â”‚      â”‚   RAG    â”‚
         â”‚                        â”‚(SQLite) â”‚      â”‚ (FAISS)  â”‚
         â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                              â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€
                              LLM (OpenAI/Ollama)
```

---

## Backend-Architektur (Python)

### Module

```
backend/
â”œâ”€â”€ api/
â”‚   â””â”€â”€ main.py                 # FastAPI REST Endpoints
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ data_agent.py          # Daten-Validierung & Kontext
â”‚   â”œâ”€â”€ analysis_agent.py      # Anomalieerkennung (ML)
â”‚   â””â”€â”€ llm_agent.py           # LLM Wrapper (OpenAI/Anthropic)
â”œâ”€â”€ database/
â”‚   â””â”€â”€ db_handler.py          # SQLite ORM
â”œâ”€â”€ rag_engine/
â”‚   â””â”€â”€ rag_manager.py         # Vector Store & Retrieval
â”œâ”€â”€ data_simulator.py          # Maschinendaten-Simulator
â”œâ”€â”€ prompt_templates.py        # Zentrale Prompts
â””â”€â”€ config.py                  # Configuration Management
```

### REST API Endpoints

| Endpoint | Methode | Beschreibung |
|----------|---------|--------------|
| `/health` | GET | Health Check + DB Stats |
| `/machines` | GET | Alle Maschinen |
| `/machines/{id}` | GET | Einzelne Maschine |
| `/measurements/{machine_id}` | GET | Sensor-Messungen |
| `/events` | GET | Events (Warnungen, Fehler) |
| `/chat` | POST | AI Chat Interface |
| `/analyze` | POST | Anomalie-Analyse |
| `/reports` | GET/POST | AI-generierte Reports |

### Datenbank-Schema

```sql
-- Maschinen
CREATE TABLE machines (
    id INTEGER PRIMARY KEY,
    name TEXT UNIQUE NOT NULL,
    type TEXT NOT NULL,
    location TEXT,
    meta_json TEXT
);

-- Sensordaten
CREATE TABLE measurements (
    id INTEGER PRIMARY KEY,
    machine_id INTEGER REFERENCES machines(id),
    timestamp TIMESTAMP NOT NULL,
    sensor_type TEXT NOT NULL,
    value REAL NOT NULL,
    unit TEXT
);

-- Events (Warnungen, Fehler)
CREATE TABLE events (
    id INTEGER PRIMARY KEY,
    machine_id INTEGER REFERENCES machines(id),
    timestamp TIMESTAMP NOT NULL,
    level TEXT CHECK(level IN ('INFO', 'WARNING', 'ERROR', 'CRITICAL')),
    message TEXT NOT NULL
);

-- AI Reports
CREATE TABLE reports (
    id INTEGER PRIMARY KEY,
    machine_id INTEGER REFERENCES machines(id),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    report_type TEXT NOT NULL,
    report_text TEXT NOT NULL
);
```

---

## Frontend-Architektur (C++ Qt)

### MVP Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   MVP Architecture                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  View    â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Presenter  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   Model    â”‚
â”‚ (UI nur) â”‚ IView   â”‚ (Logic)    â”‚         â”‚ (Data)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                    â”‚                       â”‚
      â”‚                    â”‚                       â”‚
  MainWindow        MainPresenter            DataModel
  - Charts          - Event Handling        - Cache
  - Tables          - Validation            - DTOs
  - Chat UI         - API Calls             - ApiClient
```

### Klassen-Struktur

**Model Layer** (`cpp_gui/model/`)
- `DTOs.h`: Data Transfer Objects (Machine, Measurement, Event, etc.)
- `DataModel`: Daten-Cache, Business Logic
- `ApiClient`: REST API Client (async)

**Presenter Layer** (`cpp_gui/presenter/`)
- `MainPresenter`: Orchestrierung, Event-Handling
- `IMainView`: View-Interface (Dependency Inversion)

**View Layer** (`cpp_gui/view/`)
- `MainWindow`: Qt Widgets, reine UI-Logik

### Code-Style Regeln (C++)

```cpp
// Klassen: UpperCamelCase
class MainPresenter { };

// Methoden: lowerCamelCase
void onMachineSelected(int id);

// Member-Variablen: m_ Prefix
DataModel* m_model;

// Konstanten: kUpperSnakeCase
const int kMaxRetries = 3;

// Interface: I Prefix
class IMainView { };
```

---

## AI/RAG Pipeline

### RAG Workflow

```
1. Dokument-Indexierung (Automatisch bei Simulator-Start):
   PDF/Text â†’ Text-Extraktion â†’ Chunking (500 chars, 50 overlap)
   â†’ Embeddings (all-MiniLM-L6-v2, 384-dim) â†’ FAISS Index (L2)
   â†’ Persistierung (vector_store/faiss.index + documents.txt + metadata.txt)

2. Query Processing:
   User Question â†’ Sentence-Transformer Embedding â†’ FAISS Vector Search
   â†’ Top-3 relevante Dokumente mit Score â†’ Sortierung nach Relevanz

3. LLM Context Building:
   System Prompt + RAG Dokumente (PrioritÃ¤t) + DB Context (Maschinen, Messungen, Events)
   + User Question â†’ Strukturierter Prompt fÃ¼r LLM

4. LLM Response:
   OpenAI/Anthropic â†’ Antwort + Quellenangaben (Dokument-Namen + Scores)
```

### RAG Technologie-Stack

| Komponente | Technologie | Details |
|------------|-------------|---------|
| **Vector Database** | FAISS (CPU) | L2-Distanz, 384-dimensionale Vektoren |
| **Embedding Model** | sentence-transformers/all-MiniLM-L6-v2 | 384-dim, mehrsprachig, optimiert fÃ¼r Suche |
| **PDF Extraktion** | pypdf | Text-Extraktion aus PDF-Dokumenten |
| **Chunking** | Custom Logic | 500 Zeichen, 50 Zeichen Ãœberlappung, Satzgrenzen |
| **Persistenz** | File System | `vector_store/` mit Index, Dokumente, Metadata |
| **Indexierung** | Automatisch | Bei Simulator-Start, Smart Caching, --reindex Flag |

### RAG Integration in Data Simulator

**Automatische Indexierung bei Startup:**

```python
# data_simulator.py - Zeilen 193-228
if __name__ == "__main__":
    # Check for --reindex flag
    force_reindex = "--reindex" in sys.argv
    
    # Find PDFs in backend directory
    pdfs = [f for f in os.listdir(".") if f.endswith(".pdf")]
    
    if pdfs:
        print(f"ðŸ“„ Found {len(pdfs)} PDF(s) for RAG...")
        
        # Check if vector store exists
        vector_store_path = "vector_store/faiss.index"
        
        if os.path.exists(vector_store_path) and not force_reindex:
            print("â„¹ï¸  Vector store exists. Use --reindex to rebuild.")
            print("âœ… RAG ready (use existing index)")
        else:
            # Index PDFs
            rag_manager = RAGManager()
            for pdf in pdfs:
                rag_manager.index_directory(".", file_pattern="*.pdf")
            print(f"âœ… RAG indexing complete ({len(pdfs)} PDF(s))")
    
    # Continue with simulation...
```

**Features:**
- âœ… **Smart Caching**: PrÃ¼ft ob `vector_store/faiss.index` existiert
- âœ… **Auto-Indexing**: Indexiert PDFs automatisch beim ersten Start
- âœ… **Performance**: LÃ¤dt bestehenden Index in ~100ms statt ~20s neu zu indexieren
- âœ… **Manual Rebuild**: `--reindex` Flag erzwingt Neu-Indexierung
- âœ… **Production-Ready**: Keine manuelle Indexierung notwendig

### RAG Manager API

```python
from rag_engine.rag_manager import RAGManager

# Initialisierung
rag = RAGManager(
    model_name="sentence-transformers/all-MiniLM-L6-v2",
    store_path="vector_store"
)

# Dokumente indexieren
rag.index_directory(".", file_pattern="*.pdf")

# Suche durchfÃ¼hren
results = rag.retrieve("Wie oft Wartung?", top_k=3)
# Returns: [{"text": "...", "score": 0.65, "metadata": {...}}, ...]

# Vector Store speichern (automatisch)
# LÃ¤dt beim nÃ¤chsten Start automatisch
```

### Prompt-Struktur

```python
SYSTEM_PROMPT = """
Du bist ein spezialisierter AI-Assistent fÃ¼r industrielle Maschinendatenanalyse.

Regeln:
- Faktisch basierend auf Daten
- Kennzeichne Unsicherheiten
- Nutze technische Terminologie
"""

Context = f"""
Maschine: {machine.name}
Messwerte: {recent_measurements}
Events: {recent_events}
RAG Docs: {retrieved_documents}
"""

User Query = "Was ist der Status von CNC-Mill-01?"
```

### Anomalieerkennung

**Methoden:**
1. **Z-Score**: Statistische Abweichung (3Ïƒ-Regel)
2. **IsolationForest**: ML-basierte Outlier Detection

**Workflow:**
```python
def detect_anomalies(measurements):
    # Z-Score
    mean, std = compute_stats(measurements)
    z_scores = abs((values - mean) / std)
    anomalies = values[z_scores > 3.0]
    
    # IsolationForest
    model = IsolationForest(contamination=0.1)
    predictions = model.fit_predict(values)
    
    return merge_results(anomalies, predictions)
```

---

## Deployment

### Lokale Entwicklung

```powershell
# Backend
cd backend
python -m venv venv
.\venv\Scripts\Activate.ps1
pip install -r requirements.txt
python api/main.py

# Frontend
cd cpp_gui
mkdir build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
cmake --build . --config Release
.\Release\MachinaMindAIAgent.exe
```

### Docker Deployment

```yaml
version: '3.8'

services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=sqlite:///data/MachinaData.db
    volumes:
      - ./data:/app/data

  # Optional: Lokales LLM
  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434"
```

---

## Sicherheit & Best Practices

### Backend
- âœ… Input Validation (Pydantic)
- âœ… SQL Injection Prevention (Parameterized Queries)
- âœ… API Rate Limiting (FastAPI Middleware)
- âœ… Secrets Management (.env, nicht in Git)
- âœ… CORS Configuration

### Frontend
- âœ… HTTPS fÃ¼r Produktion
- âœ… Error Handling (try-catch)
- âœ… Memory Management (RAII, Smart Pointers)
- âœ… Thread Safety (Async Network Calls)

---

## Performance

### Backend
- **Request Latency**: < 100ms (ohne LLM)
- **LLM Latency**: 2-5s (abhÃ¤ngig von Modell)
- **DB Queries**: Indiziert (< 10ms)
- **RAG Retrieval**: < 50ms (FAISS)

### Frontend
- **UI Responsiveness**: 60 FPS
- **Chart Updates**: Async (nicht blockierend)
- **Memory**: < 200MB (idle)

---

## Testing-Strategie

### Backend
```bash
pytest tests/ -v --cov=backend
```

**Test-Typen:**
- Unit Tests: Agents, DB Handler
- Integration: API Endpoints (mocked LLM)
- Performance: Latency, Throughput

### Frontend
```bash
cd cpp_gui/build
ctest --output-on-failure
```

**Test-Typen:**
- Unit Tests: Presenter Logic (Google Test)
- Integration: API Client (Mock Server)
- UI Tests: Qt Test Framework

---

## Monitoring & Logging

### Backend Logging
```python
from loguru import logger

logger.info("API request received")
logger.error("Database connection failed")
```

**Strukturierte Logs (JSON):**
```json
{
  "timestamp": "2025-10-20T10:30:00",
  "level": "INFO",
  "message": "Chat request processed",
  "machine_id": 1,
  "latency_ms": 45
}
```

### Frontend Logging
- Console Output (Debug Mode)
- Log-Datei (Production)
- Error Reports an Backend

